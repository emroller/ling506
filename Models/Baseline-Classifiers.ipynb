{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: emoji in /Users/emilyroller/Library/Python/3.8/lib/python/site-packages (1.6.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: mlxtend in /Users/emilyroller/Library/Python/3.8/lib/python/site-packages (0.19.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20.3 in /Users/emilyroller/Library/Python/3.8/lib/python/site-packages (from mlxtend) (0.24.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.24.2 in /Users/emilyroller/Library/Python/3.8/lib/python/site-packages (from mlxtend) (1.2.3)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from mlxtend) (41.2.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.16.2 in /Users/emilyroller/Library/Python/3.8/lib/python/site-packages (from mlxtend) (1.20.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.13.2 in /Users/emilyroller/Library/Python/3.8/lib/python/site-packages (from mlxtend) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib>=3.0.0 in /Users/emilyroller/Library/Python/3.8/lib/python/site-packages (from mlxtend) (3.4.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.2.1 in /Users/emilyroller/Library/Python/3.8/lib/python/site-packages (from mlxtend) (1.6.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/emilyroller/Library/Python/3.8/lib/python/site-packages (from scikit-learn>=0.20.3->mlxtend) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /Users/emilyroller/Library/Python/3.8/lib/python/site-packages (from pandas>=0.24.2->mlxtend) (2021.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /Users/emilyroller/Library/Python/3.8/lib/python/site-packages (from pandas>=0.24.2->mlxtend) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /Users/emilyroller/Library/Python/3.8/lib/python/site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /Users/emilyroller/Library/Python/3.8/lib/python/site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.2.1 in /Users/emilyroller/Library/Python/3.8/lib/python/site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in /Users/emilyroller/Library/Python/3.8/lib/python/site-packages (from matplotlib>=3.0.0->mlxtend) (8.3.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->mlxtend) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install emoji --upgrade --user\n",
    "!{sys.executable} -m pip install mlxtend --upgrade --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import pandas\n",
    "import numpy\n",
    "import string\n",
    "import emoji\n",
    "import re\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data tweets and corresponding labels\n",
    "trainDF = pandas.read_csv('../Data/sarcasm_db.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are three text processing options:\n",
      "1. Keeping emojis in as their emoji representation (text)\n",
      "2. Keeping emojis in as their text description representation (parsed with emojis)\n",
      "3. Removing all and any emoji representations (parsed without emojis)\n",
      "Choose from one: text, parsed with emojis, parsed without emojis\n",
      "text\n"
     ]
    }
   ],
   "source": [
    "options = ['text', 'parsed with emojis', 'parsed without emojis']\n",
    "print('There are three text processing options:')\n",
    "print('1. Keeping emojis in as their emoji representation (text)')\n",
    "print('2. Keeping emojis in as their text description representation (parsed with emojis)')\n",
    "print('3. Removing all and any emoji representations (parsed without emojis)')\n",
    "\n",
    "opt = input(\"Choose from one: text, parsed with emojis, parsed without emojis\\n\").lower()\n",
    "while opt.strip() not in options:\n",
    "    opt = input(\"Not a valid option! Choose from one: text, parsed with emojis, parsed without emojis\\n\").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF[opt], trainDF['sarcasm labels'], test_size=0.10, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(trainDF[opt])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,4), max_features=None)\n",
    "tfidf_vect_ngram.fit(trainDF[opt])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracy for text data ...\n",
      "\n",
      "Dummy classifier, uniform : 0.5210643015521065\n",
      "Dummy classifier, stratified : 0.49223946784922396\n",
      "Dummy classifier, most_frequent : 0.49889135254988914\n",
      "Naive-Bayes N-Gram Vectors :  0.7594235033259423\n",
      "K-Neighbors : 0.9212860310421286\n"
     ]
    }
   ],
   "source": [
    "print('Calculating accuracy for ' + opt + ' data ...\\n')\n",
    "strategies = ['uniform', 'stratified', 'most_frequent']\n",
    "  \n",
    "for s in strategies:\n",
    "    dclf = DummyClassifier(strategy = s, random_state = 1234)\n",
    "    accuracy = train_model(dclf, xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "    print('Dummy classifier,', s, ':', accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"Naive-Bayes N-Gram Vectors : \", accuracy)\n",
    "\n",
    "accuracy = train_model(KNeighborsClassifier(n_neighbors = 5), xtrain_count, train_y, xvalid_count)\n",
    "print('K-Neighbors :', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
